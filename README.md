# â˜ï¸ Cloud Data Engineering â€” End-to-End ETL Pipeline
**Python â€¢ Apache Airflow â€¢ dbt â€¢ Snowflake â€¢ PostgreSQL â€¢ Docker â€¢ Power BI**

Este repositÃ³rio apresenta a construÃ§Ã£o de um **pipeline de dados end-to-end em ambiente cloud**, cobrindo **ingestÃ£o, orquestraÃ§Ã£o, transformaÃ§Ã£o, modelagem analÃ­tica e qualidade de dados**, seguindo boas prÃ¡ticas modernas de **Data Engineering e Analytics Engineering**.

O projeto foi desenhado para simular um **cenÃ¡rio real de produÃ§Ã£o**, indo alÃ©m de soluÃ§Ãµes totalmente gerenciadas, com foco em **infraestrutura, automaÃ§Ã£o, versionamento e observabilidade**.

---

## ğŸ¯ Objetivos do Projeto

- Construir um pipeline **completo**, desde dados brutos atÃ© camadas analÃ­ticas.
- Trabalhar com **dados externos** (API pÃºblica e dataset real).
- Implementar **orquestraÃ§Ã£o automatizada** com dependÃªncias, retries e logs.
- Aplicar **Medallion Architecture (Bronze, Silver, Gold)** usando dbt.
- Garantir **qualidade de dados** via testes automatizados.
- Simular um ambiente prÃ³ximo ao **dia a dia de um Data Engineer em cloud**.

---

## ğŸ§± Stack TecnolÃ³gica

### â˜ï¸ Infraestrutura & DevOps
- **Cloud Provider:** DigitalOcean
- **Ambiente:** Linux VM (Droplet)
- **ContainerizaÃ§Ã£o:** Docker & Docker Compose
- **CI:** GitHub Actions

> Escolha proposital para aprender conceitos reais de infraestrutura, deploy e isolamento de ambientes.

---

### ğŸ—„ï¸ Camada de Dados
- **PostgreSQL**
- **Snowflake** (Data Warehouse AnalÃ­tico)

UtilizaÃ§Ã£o:
- **Bronze:** dados brutos ingeridos
- **Silver:** dados tratados e padronizados
- **Gold:** dados modelados para analytics e BI

---

### ğŸ”Œ IngestÃ£o de Dados
- **Python**
  - `requests`
  - `pandas`
  - `SQLAlchemy`

**Responsabilidades:**
- ExtraÃ§Ã£o de dados (API pÃºblica / CSV real)
- PadronizaÃ§Ã£o tÃ©cnica mÃ­nima de schema
- PersistÃªncia **sem regras de negÃ³cio** na camada Bronze

---

### ğŸ”„ OrquestraÃ§Ã£o
- **Apache Airflow**

**Funcionalidades implementadas:**
- DAGs end-to-end
- Controle de dependÃªncias
- Retries automÃ¡ticos
- Scheduling e backfill
- Logs, Grid View e Gantt View para observabilidade

---

### ğŸ§ª TransformaÃ§Ã£o & Modelagem
- **dbt Core**

**Boas prÃ¡ticas aplicadas:**
- SQL versionado
- Modelagem incremental
- Medallion Architecture
- SeparaÃ§Ã£o entre lÃ³gica tÃ©cnica e de negÃ³cio

**Camadas:**
- **Bronze:** espelhamento do raw
- **Silver:** limpeza, tipagem, deduplicaÃ§Ã£o
- **Gold:** mÃ©tricas e tabelas analÃ­ticas

**Qualidade de Dados:**
- `not_null`
- `unique`
- testes customizados via dbt

---

### ğŸ“Š Consumo AnalÃ­tico
- **Power BI**

**KPIs e AnÃ¡lises:**
- Taxa de Churn (%)
- SegmentaÃ§Ã£o geogrÃ¡fica
- Comportamento do cliente
- Uso de produtos e impacto na retenÃ§Ã£o

---

## ğŸ“… Linha do Tempo do Projeto

### ğŸ—ï¸ Fase 1 â€” FundaÃ§Ã£o e Infraestrutura
- ConfiguraÃ§Ã£o do `docker-compose.yaml`
- Deploy do Apache Airflow
- CriaÃ§Ã£o dos schemas `BRONZE`, `SILVER`, `GOLD`

---

### ğŸ“¥ Fase 2 â€” IngestÃ£o & OrquestraÃ§Ã£o
- Desenvolvimento do script Python de ingestÃ£o
- PadronizaÃ§Ã£o tÃ©cnica de colunas
- Carga automÃ¡tica na camada Bronze
- CriaÃ§Ã£o da primeira DAG no Airflow

---

### ğŸ§  Fase 3 â€” Analytics Engineering
- Modelos dbt para Silver e Gold
- ImplementaÃ§Ã£o de regras de negÃ³cio
- Testes automatizados de qualidade
- OrquestraÃ§Ã£o do `dbt run` via Airflow

---

### ğŸ“ˆ Fase 4 â€” Entrega de Valor
- ConexÃ£o do Power BI Ã  camada Gold
- ConstruÃ§Ã£o de dashboards estratÃ©gicos
- GeraÃ§Ã£o de insights para retenÃ§Ã£o de clientes

---

## ğŸ¦ Caso de Uso: Churn BancÃ¡rio

Pipeline focado em **retenÃ§Ã£o de clientes bancÃ¡rios**, transformando dados operacionais em inteligÃªncia estratÃ©gica.

**Principais anÃ¡lises:**
- Taxa geral de churn
- Churn por paÃ­s (FranÃ§a, Alemanha, Espanha)
- RelaÃ§Ã£o entre produtos, atividade do cliente e churn

---

## ğŸ› ï¸ Skills Aplicadas

| Skill | Categoria |
|-----|---------|
| Apache Airflow | OrquestraÃ§Ã£o |
| dbt (data build tool) | TransformaÃ§Ã£o |
| SQL (PostgreSQL / Snowflake) | Data Warehouse |
| Python (ETL) | Engenharia de Dados |
| Docker & Docker Compose | Infraestrutura |
| Power BI | VisualizaÃ§Ã£o |
| Git & GitHub Actions | Versionamento & CI |

---

## ğŸš€ Como Executar o Projeto

```bash
# Subir o ambiente
docker-compose up -d
Acessar o Airflow em http://localhost:8080

Ativar a DAG pipeline_churn_bancario_end_to_end

Aguardar a execuÃ§Ã£o completa

Consultar os dados nas camadas Silver e Gold

Abrir o arquivo .pbix no Power BI para visualizar os dashboards
```
